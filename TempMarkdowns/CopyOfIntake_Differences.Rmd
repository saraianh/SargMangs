---
title: "Intake Differences by Species, Treatment, and Site (RHMA vs LARA)"
author: "Sarai Hutchinson"
date: "2025-09-23"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    number_sections: true
params:
  out_dir:  "intake_outputs"
---

What This Script Does:

1. Sets up all necessary libraries and plotting aesthetics
2. Imports and cleans your RHMA data with robust date parsing
3. Maps treatments to readable names (A→Soil, B→Crushed glass, etc.)
4. Detects outliers using the IQR method
5. Generates summary statistics by site and treatment
6. Tests statistical assumptions (normality and homogeneity)
7. Runs appropriate tests (nonparametric if assumptions violated, parametric if met)
8. Provides comprehensive diagnostics and data availability summaries
9. Includes optional file exports for all results

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                     fig.width = 9, fig.height = 6)

# Libraries
suppressPackageStartupMessages({
  library(tidyverse)
  library(lubridate)
  library(janitor)
  library(car)
  library(FSA)
  library(rstatix)
})

set.seed(20250901)

# Aesthetics
okabe_ito <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", 
               "#0072B2", "#D55E00", "#CC79A7", "#999999")

# Define units mapping for traits
trait_units <- list(
  # RHMA traits
  "diameter" = "mm",
  "epi_length" = "cm", 
  "hypo_length" = "cm",
  "total_height" = "cm",
  "mass" = "g",
  # LARA traits  
  "width" = "mm",
  "prop_length" = "cm",
  "rad_length" = "cm", 
  "total_length" = "cm"
)

# Treatment mapping
treatment_map <- c("A" = "Soil", "B" = "Crushed glass", "C" = "25% SG", 
                   "D" = "75% SG", "E" = "100% Sargassum (SG)")

# Define colors using okabe_ito palette
color_vals <- c(
  "Soil"                = okabe_ito[1], # green  (#009E73)
  "Crushed glass"       = okabe_ito[6], # blue   (#0072B2)
  "25% SG"              = okabe_ito[3], # orange (#E69F00)
  "75% SG"              = okabe_ito[2], # vermillion (#D55E00)
  "100% Sargassum (SG)" = okabe_ito[7]  # purple (#CC79A7)
)

# Helper functions
parse_mdy_relaxed <- function(x) {
  suppressWarnings(parse_date_time(x, orders = c("mdy", "mdy HM", "mdy HMS")))
}

clean_numeric <- function(x) {
  suppressWarnings(as.numeric(str_replace_all(x, ",", "")))
}

# Ensure 'params$out_dir' exists even if not rendered via params:
if (!exists("params") || is.null(params$out_dir)) {
  params <- list(out_dir = "analysis_outputs")
}
dir.create(params$out_dir, showWarnings = FALSE, recursive = TRUE)

# Make sure site is a factor and drop empty levels later
.make_site_factor <- function(df) {
  df %>% mutate(site = forcats::fct_drop(as.factor(site)))
}

detect_outliers <- function(data, traits) {
  data %>%
    pivot_longer(all_of(traits), names_to = "trait", values_to = "value") %>%
    group_by(trait) %>%
    mutate(
      iqr = IQR(value, na.rm = TRUE),
      Q1 = quantile(value, 0.25, na.rm = TRUE),
      Q3 = quantile(value, 0.75, na.rm = TRUE),
      is_outlier = value < (Q1 - 3*iqr) | value > (Q3 + 3*iqr)
    ) %>%
    ungroup() %>%
    filter(is_outlier & !is.na(value))
}

check_assumptions <- function(data, traits, group_vars = c("site", "treatment")) {
  map_dfr(traits, function(tr) {
    df <- data %>% select(all_of(c(group_vars, tr))) %>% drop_na()
    if (nrow(df) < 8) return(tibble(trait = tr, shapiro_p = NA, levene_p = NA))
    
    # Fit model and check assumptions
    f <- lm(reformulate(paste(group_vars, collapse = "*"), response = tr), data = df)
    shapiro_p <- tryCatch(shapiro.test(residuals(f))$p.value, error = function(e) NA)
    levene_p <- tryCatch(
      car::leveneTest(df[[tr]] ~ interaction(df[[group_vars[1]]], df[[group_vars[2]]]))$`Pr(>F)`[1],
      error = function(e) NA
    )
    
    tibble(trait = tr, shapiro_p = shapiro_p, levene_p = levene_p)
  })
}

run_nonparametric_tests <- function(data, traits) {
  # Kruskal-Wallis tests
  kw_results <- map_dfr(traits, function(tr) {
    df <- data %>% select(site, treatment, value = all_of(tr)) %>% drop_na()
    map_dfr(unique(df$site), function(si) {
      sub <- df %>% filter(site == si)
      if (n_distinct(sub$treatment) > 1 && nrow(sub) > 2) {
        kw <- kruskal.test(value ~ treatment, data = sub)
        tibble(trait = tr, site = si, 
               statistic = unname(kw$statistic), p_value = kw$p.value)
      } else {
        tibble(trait = tr, site = si, statistic = NA, p_value = NA)
      }
    })
  })
  
  # Dunn pairwise tests using rstatix (more reliable)
  dunn_results <- map_dfr(traits, function(tr) {
    df <- data %>% select(site, treatment, value = all_of(tr)) %>% drop_na()
    map_dfr(unique(df$site), function(si) {
      sub <- df %>% filter(site == si)
      if (n_distinct(sub$treatment) > 1 && nrow(sub) > 2) {
        tryCatch({
          # Use rstatix dunn_test instead of FSA
          out <- sub %>%
            dunn_test(value ~ treatment, p.adjust.method = "bonferroni") %>%
            mutate(trait = tr, site = si)
          out
        }, error = function(e) {
          cat("Error in Dunn test for", tr, "at site", si, ":", e$message, "\n")
          tibble()
        })
      } else {
        tibble()
      }
    })
  })
  
  list(kruskal_wallis = kw_results, dunn_pairwise = dunn_results)
}

create_boxplots <- function(data, traits, species_name, trait_units = NULL) {
  
  # Use default units if none provided
  if (is.null(trait_units)) {
    trait_units <- list(
      # RHMA traits
      "diameter" = "mm",
      "epi_length" = "cm", 
      "hypo_length" = "cm",
      "total_height" = "cm",
      "mass" = "g",
      # LARA traits  
      "width" = "mm",
      "prop_length" = "cm",
      "rad_length" = "cm", 
      "total_length" = "cm"
    )
  }

    # Create labeled data with units
  plot_data <- data %>%
    pivot_longer(all_of(traits), names_to = "trait") %>%
    mutate(      
      # Recode treatment names and convert to ordered factor
      treatment = dplyr::recode(treatment, !!!treatment_map),
      treatment = factor(
        treatment,
        levels = c("Soil", "Crushed glass", "25% SG", "75% SG", "100% Sargassum (SG)")
      )
    ) %>%
    # Add trait labels in a separate step to avoid case_when() evaluation issues
    rowwise() %>%
    mutate(
      trait_label = {
        base_label <- str_to_title(gsub("_", " ", trait))
        if (trait %in% names(trait_units)) {
          paste0(base_label, " (", trait_units[[trait]], ")")
        } else {
          base_label
        }
      }
    ) %>%
    ungroup()
  
  # Create the plot
  plot_data %>%
    ggplot(aes(x = treatment, y = value, fill = treatment)) +
    geom_boxplot(outlier.alpha = 0.5, alpha = 0.7) +
    geom_jitter(width = 0.15, alpha = 0.4, size = 1) +
    scale_fill_manual(values = color_vals) +
    facet_grid(trait_label ~ site, scales = "free_y", 
               labeller = labeller(trait_label = label_wrap_gen(15))) +
    labs(x = "Treatment", y = "Measurement") +
    theme_bw(base_size = 11) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none",
      strip.text = element_text(size = 10),
      strip.text.y = element_text(size = 9)  # Slightly smaller for trait labels with units
    )
}

suppressPackageStartupMessages({
  library(multcompView)  # for multcompLetters()
})

# Compute CLD letters from a pairwise table (group1, group2, p.adj)
.cld_from_pairs <- function(pairs_tbl, level_order) {
  if (nrow(pairs_tbl) == 0) {
    return(tibble(group = factor(level_order, levels = level_order), Letters = ""))
  }
  # Build a full p-value matrix in the specified order
  lv <- level_order
  M <- matrix(1, nrow = length(lv), ncol = length(lv), dimnames = list(lv, lv))
  for (i in seq_len(nrow(pairs_tbl))) {
    g1 <- as.character(pairs_tbl$group1[i])
    g2 <- as.character(pairs_tbl$group2[i])
    p  <- as.numeric(pairs_tbl$p.adj[i])
    if (!is.na(g1) && !is.na(g2) && !is.na(p) && g1 %in% lv && g2 %in% lv) {
      M[g1, g2] <- p
      M[g2, g1] <- p
    }
  }
  # multcompLetters wants a named vector of p-values for all pairs (upper triangle)
  pv_named <- c()
  for (i in seq_along(lv)) for (j in (i+1):length(lv)) {
    if (j <= length(lv)) {
      nm <- paste(lv[i], lv[j], sep = "-")
      pv_named[nm] <- M[lv[i], lv[j]]
    }
  }
  L <- multcompView::multcompLetters(pv_named, threshold = 0.05)$Letters
  tibble(group = factor(names(L), levels = level_order),
         Letters = unname(L))
}

# Prepare per-panel y positions (keeps letters above the tallest point in each panel)
.panel_y_positions <- function(data_long, panel_vars, x_var, y_var = "value", bump = 0.06) {
  # bump is fraction of panel range to place letters above the max
  data_long %>%
    group_by(across(all_of(panel_vars))) %>%
    summarise(y_min = min(.data[[y_var]], na.rm = TRUE),
              y_max = max(.data[[y_var]], na.rm = TRUE),
              .groups = "drop") %>%
    mutate(y_pos_panel = y_max + (y_max - y_min) * bump)
}
```


```{r include=FALSE}
# Enhanced functions to capture all required statistics for proper reporting

check_assumptions_complete <- function(data, traits, group_vars = c("site", "treatment")) {
  map_dfr(traits, function(tr) {
    df <- data %>% select(all_of(c(group_vars, tr))) %>% drop_na()
    if (nrow(df) < 8) {
      return(tibble(
        trait = tr, 
        shapiro_W = NA, shapiro_df = NA, shapiro_p = NA,
        levene_F = NA, levene_df1 = NA, levene_df2 = NA, levene_p = NA,
        n_total = nrow(df)
      ))
    }
    
    # Fit model for residuals
    f <- lm(reformulate(paste(group_vars, collapse = "*"), response = tr), data = df)
    residuals_f <- residuals(f)
    
    # Shapiro-Wilk test on residuals
    shapiro_result <- tryCatch({
      shapiro.test(residuals_f)
    }, error = function(e) list(statistic = NA, p.value = NA))
    
    # Levene's test for homogeneity of variance
    levene_result <- tryCatch({
      car::leveneTest(df[[tr]] ~ interaction(df[[group_vars[1]]], df[[group_vars[2]]]))
    }, error = function(e) {
      data.frame(Df = c(NA, NA), `F value` = c(NA, NA), `Pr(>F)` = c(NA, NA))
    })
    
    tibble(
      trait = tr,
      shapiro_W = unname(shapiro_result$statistic),
      shapiro_df = length(residuals_f),
      shapiro_p = shapiro_result$p.value,
      levene_F = levene_result$`F value`[1],
      levene_df1 = levene_result$Df[1],
      levene_df2 = levene_result$Df[2], 
      levene_p = levene_result$`Pr(>F)`[1],
      n_total = nrow(df)
    )
  })
}

run_kruskal_wallis_complete <- function(data, traits) {
  map_dfr(traits, function(tr) {
    df <- data %>% select(site, treatment, value = all_of(tr)) %>% drop_na()
    map_dfr(unique(df$site), function(si) {
      sub <- df %>% filter(site == si)
      if (n_distinct(sub$treatment) > 1 && nrow(sub) > 2) {
        
        # Get sample sizes per group
        group_sizes <- sub %>% count(treatment, name = "n_group")
        
        # Kruskal-Wallis test
        kw <- kruskal.test(value ~ treatment, data = sub)
        
        # Calculate degrees of freedom (k-1 where k = number of groups)
        df_kw <- n_distinct(sub$treatment) - 1
        
        tibble(
          trait = tr, 
          site = si,
          H_statistic = unname(kw$statistic),
          df = df_kw,
          p_value = kw$p.value,
          n_total = nrow(sub),
          n_groups = n_distinct(sub$treatment),
          group_sizes = list(group_sizes),
          significant = ifelse(kw$p.value < 0.05, "Yes", "No"),
          effect_interpretation = case_when(
            kw$p.value < 0.001 ~ "Strong evidence against null hypothesis",
            kw$p.value < 0.01 ~ "Moderate evidence against null hypothesis", 
            kw$p.value < 0.05 ~ "Weak evidence against null hypothesis",
            TRUE ~ "Insufficient evidence to reject null hypothesis"
          )
        )
      } else {
        tibble(trait = tr, site = si, H_statistic = NA, df = NA, p_value = NA,
               n_total = nrow(sub), n_groups = n_distinct(sub$treatment),
               group_sizes = NA, significant = "Cannot test", effect_interpretation = "Insufficient groups")
      }
    })
  })
}

run_dunn_complete <- function(data, traits) {
  map_dfr(traits, function(tr) {
    df <- data %>% select(site, treatment, value = all_of(tr)) %>% drop_na()
    map_dfr(unique(df$site), function(si) {
      sub <- df %>% filter(site == si)
      if (n_distinct(sub$treatment) > 1 && nrow(sub) > 2) {
        tryCatch({
          # Use rstatix dunn_test with effect size
          out <- sub %>%
            dunn_test(value ~ treatment, p.adjust.method = "bonferroni") %>%
            mutate(
              trait = tr, 
              site = si,
              comparison = paste(group1, "vs", group2),
              effect_size_r = abs(statistic) / sqrt(n1 + n2), # approximation of effect size
              magnitude = case_when(
                effect_size_r < 0.3 ~ "Small",
                effect_size_r < 0.5 ~ "Medium", 
                TRUE ~ "Large"
              ),
              significance_level = case_when(
                p.adj < 0.001 ~ "p < 0.001",
                p.adj < 0.01 ~ "p < 0.01",
                p.adj < 0.05 ~ "p < 0.05",
                TRUE ~ "ns"
              )
            )
          out
        }, error = function(e) {
          cat("Error in Dunn test for", tr, "at site", si, ":", e$message, "\n")
          tibble()
        })
      } else {
        tibble()
      }
    })
  })
}

# Function to create properly formatted statistical reports
create_assumption_report <- function(assumptions_df) {
  assumptions_df %>%
    mutate(
      shapiro_report = sprintf("W = %.4f, df = %d, p = %.4f", shapiro_W, shapiro_df, shapiro_p),
      levene_report = sprintf("F(%d, %d) = %.4f, p = %.4f", levene_df1, levene_df2, levene_F, levene_p),
      normality_conclusion = case_when(
        is.na(shapiro_p) ~ "Cannot assess",
        shapiro_p >= 0.05 ~ "Normal distribution (fail to reject H₀)",
        TRUE ~ "Non-normal distribution (reject H₀)"
      ),
      homogeneity_conclusion = case_when(
        is.na(levene_p) ~ "Cannot assess", 
        levene_p >= 0.05 ~ "Equal variances (fail to reject H₀)",
        TRUE ~ "Unequal variances (reject H₀)"
      )
    )
}

create_kruskal_report <- function(kw_df) {
  kw_df %>%
    mutate(
      kw_report = sprintf("H(%d) = %.4f, p = %.4f", df, H_statistic, p_value),
      sample_size_report = sprintf("N = %d across %d groups", n_total, n_groups)
    )
}

create_dunn_report <- function(dunn_df) {
  dunn_df %>%
    filter(!is.na(p.adj) & p.adj < 0.05) %>%
    mutate(
      dunn_report = sprintf("Z = %.3f, p_adj = %.4f, r = %.3f (%s effect)", 
                           statistic, p.adj, effect_size_r, magnitude),
      group_sizes = sprintf("n₁ = %d, n₂ = %d", n1, n2)
    ) %>%
    select(trait, site, comparison, dunn_report, group_sizes, significance_level)
}

# Function to save tables to output directory
save_publication_tables <- function(tables_list, species_name, out_dir) {
  
  # Create output directory if it doesn't exist
  if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
  
  species_prefix <- tolower(species_name)
  
  # Save raw data as CSV
  write_csv(tables_list$assumptions, 
            file.path(out_dir, paste0(species_prefix, "_assumption_tests.csv")))
  
  write_csv(tables_list$kruskal_wallis, 
            file.path(out_dir, paste0(species_prefix, "_kruskal_wallis_tests.csv")))
  
  write_csv(tables_list$pairwise_comparisons, 
            file.path(out_dir, paste0(species_prefix, "_pairwise_comparisons.csv")))
  
  # Save formatted tables as HTML
  knitr::kable(tables_list$assumptions, format = "html", 
               caption = paste(species_name, ": Tests of Statistical Assumptions")) %>%
    writeLines(file.path(out_dir, paste0(species_prefix, "_table1_assumptions.html")))
  
  knitr::kable(tables_list$kruskal_wallis, format = "html",
               caption = paste(species_name, ": Overall Treatment Effects by Site")) %>%
    writeLines(file.path(out_dir, paste0(species_prefix, "_table2_kruskal_wallis.html")))
  
  knitr::kable(tables_list$pairwise_comparisons, format = "html",
               caption = paste(species_name, ": Significant Post-hoc Comparisons (Bonferroni-corrected)")) %>%
    writeLines(file.path(out_dir, paste0(species_prefix, "_table3_pairwise.html")))
  
  # Save formatted text output
  sink(file.path(out_dir, paste0(species_prefix, "_formatted_tables.txt")))
  
  cat("=== ", toupper(species_name), " PUBLICATION-READY TABLES ===\n\n")
  
  cat("Table 1: Assumption Testing Results\n")
  cat("===================================\n")
  print(knitr::kable(tables_list$assumptions, format = "markdown",
                    caption = paste(species_name, ": Tests of Statistical Assumptions")))
  
  cat("\n\nTable 2: Kruskal-Wallis Test Results\n") 
  cat("====================================\n")
  print(knitr::kable(tables_list$kruskal_wallis, format = "markdown",
                    caption = paste(species_name, ": Overall Treatment Effects by Site")))
  
  cat("\n\nTable 3: Significant Pairwise Comparisons\n")
  cat("=========================================\n")
  print(knitr::kable(tables_list$pairwise_comparisons, format = "markdown",
                    caption = paste(species_name, ": Significant Post-hoc Comparisons (Bonferroni-corrected)")))
  
  sink()
  
  # Create a summary report
  sink(file.path(out_dir, paste0(species_prefix, "_summary_report.txt")))
  
  cat("=== ", toupper(species_name), " ANALYSIS SUMMARY ===\n\n")
  cat("Files created:\n")
  cat("- ", species_prefix, "_assumption_tests.csv (raw data)\n", sep = "")
  cat("- ", species_prefix, "_kruskal_wallis_tests.csv (raw data)\n", sep = "")
  cat("- ", species_prefix, "_pairwise_comparisons.csv (raw data)\n", sep = "")
  cat("- ", species_prefix, "_table1_assumptions.html (formatted)\n", sep = "")
  cat("- ", species_prefix, "_table2_kruskal_wallis.html (formatted)\n", sep = "")
  cat("- ", species_prefix, "_table3_pairwise.html (formatted)\n", sep = "")
  cat("- ", species_prefix, "_formatted_tables.txt (text format)\n", sep = "")
  cat("- ", species_prefix, "_summary_report.txt (this file)\n", sep = "")
  
  cat("\n\nAnalysis Summary:\n")
  cat("- Assumption tests: ", nrow(tables_list$assumptions), " traits tested\n", sep = "")
  cat("- Kruskal-Wallis tests: ", nrow(tables_list$kruskal_wallis), " trait-site combinations\n", sep = "")
  cat("- Significant pairwise comparisons: ", nrow(tables_list$pairwise_comparisons), "\n", sep = "")
  
  normality_violations <- sum(tables_list$assumptions$Normality == "Violated", na.rm = TRUE)
  homogeneity_violations <- sum(tables_list$assumptions$Homogeneity == "Violated", na.rm = TRUE)
  significant_kw <- sum(tables_list$kruskal_wallis$Result == "Significant", na.rm = TRUE)
  
  cat("- Normality violations: ", normality_violations, "/", nrow(tables_list$assumptions), "\n", sep = "")
  cat("- Homogeneity violations: ", homogeneity_violations, "/", nrow(tables_list$assumptions), "\n", sep = "")
  cat("- Significant overall effects: ", significant_kw, "/", nrow(tables_list$kruskal_wallis), "\n", sep = "")
  
  sink()
  
  cat("Tables saved to:", out_dir, "\n")
  cat("Files created for", species_name, ":\n")
  cat("  - CSV files (raw data)\n")
  cat("  - HTML files (formatted tables)\n") 
  cat("  - TXT files (markdown format)\n")
  cat("  - Summary report\n\n")
}

# Complete reporting functions for both species
generate_complete_report <- function(data, traits, species_name) {
  
  cat(sprintf("=== COMPREHENSIVE %s STATISTICAL REPORT ===\n\n", toupper(species_name)))
  
  # Complete assumption checks
  cat("ASSUMPTION TESTING\n")
  cat("==================\n")
  cat("Shapiro-Wilk tests were conducted on model residuals to assess normality.\n")
  cat("Levene's tests were conducted to assess homogeneity of variance.\n\n")
  
  assumptions <- check_assumptions_complete(data, traits)
  assumption_report <- create_assumption_report(assumptions)
  
  for(i in 1:nrow(assumption_report)) {
    row <- assumption_report[i,]
    cat(sprintf("**%s (N = %d)**\n", row$trait, row$n_total))
    cat(sprintf("Shapiro-Wilk: %s → %s\n", row$shapiro_report, row$normality_conclusion))
    cat(sprintf("Levene's test: %s → %s\n\n", row$levene_report, row$homogeneity_conclusion))
  }
  
  # Complete Kruskal-Wallis tests
  cat("OVERALL GROUP DIFFERENCES (Kruskal-Wallis Tests)\n")
  cat("=================================================\n")
  cat("Due to violated assumptions, nonparametric Kruskal-Wallis tests were conducted.\n\n")
  
  kw_results <- run_kruskal_wallis_complete(data, traits)
  kw_report <- create_kruskal_report(kw_results)
  
  for(i in 1:nrow(kw_report)) {
    row <- kw_report[i,]
    cat(sprintf("**%s at %s site**\n", row$trait, row$site))
    cat(sprintf("Kruskal-Wallis: %s, %s\n", row$kw_report, row$sample_size_report))
    cat(sprintf("Result: %s - %s\n\n", row$significant, row$effect_interpretation))
  }
  
  # Complete post-hoc tests
  cat("POST-HOC PAIRWISE COMPARISONS (Dunn's Tests)\n") 
  cat("=============================================\n")
  cat("Bonferroni-corrected Dunn's tests were conducted for significant Kruskal-Wallis results.\n\n")
  
  dunn_results <- run_dunn_complete(data, traits)
  dunn_report <- create_dunn_report(dunn_results)
  
  if(nrow(dunn_report) > 0) {
    current_trait <- ""
    current_site <- ""
    for(i in 1:nrow(dunn_report)) {
      row <- dunn_report[i,]
      if(row$trait != current_trait || row$site != current_site) {
        cat(sprintf("\n**%s at %s site:**\n", row$trait, row$site))
        current_trait <- row$trait
        current_site <- row$site
      }
      cat(sprintf("• %s: %s (%s), %s\n", 
                 row$comparison, row$dunn_report, row$group_sizes, row$significance_level))
    }
  } else {
    cat("No significant pairwise differences found after Bonferroni correction.\n")
  }
  
  cat("\n")
  cat(paste(rep("=", 60), collapse = ""))
  cat("\n")
  
  return(list(assumptions = assumptions, kruskal_wallis = kw_results, dunn_tests = dunn_results))
}

# Usage example:
# rhma_complete_results <- generate_complete_report(rhma_clean, rhma_traits, "RHMA")
# lara_complete_results <- generate_complete_report(lara_clean, lara_traits, "LARA")

# Function to create publication-ready tables
create_publication_table <- function(results_list, species_name) {
  
  # Assumption checks table
  assumptions_table <- results_list$assumptions %>%
    select(trait, shapiro_W, shapiro_df, shapiro_p, levene_F, levene_df1, levene_df2, levene_p) %>%
    mutate(
      shapiro_report = sprintf("%.3f (%d)", shapiro_W, shapiro_df),
      levene_report = sprintf("%.3f (%d, %d)", levene_F, levene_df1, levene_df2),
      normality = ifelse(shapiro_p < 0.05, "Violated", "OK"),
      homogeneity = ifelse(levene_p < 0.05, "Violated", "OK")
    ) %>%
    select(Trait = trait, `Shapiro-Wilk W (df)` = shapiro_report, 
           `p-value` = shapiro_p, Normality = normality,
           `Levene's F (df1, df2)` = levene_report, 
           `p-value ` = levene_p, Homogeneity = homogeneity)
  
  # Kruskal-Wallis results table  
  kw_table <- results_list$kruskal_wallis %>%
    filter(!is.na(H_statistic)) %>%
    mutate(
      kw_statistic = sprintf("%.3f (%d)", H_statistic, df),
      significance = ifelse(p_value < 0.05, "Significant", "Non-significant")
    ) %>%
    select(Trait = trait, Site = site, `H (df)` = kw_statistic, 
           `p-value` = p_value, `N` = n_total, Result = significance)
  
  # Significant pairwise comparisons table
  dunn_table <- results_list$dunn_tests %>%
    filter(!is.na(p.adj) & p.adj < 0.05) %>%
    mutate(
      effect_size_report = sprintf("%.3f (%s)", effect_size_r, magnitude),
      sample_sizes = sprintf("%d vs %d", n1, n2)
    ) %>%
    select(Trait = trait, Site = site, Comparison = comparison,
           `Z-statistic` = statistic, `p-adjusted` = p.adj, 
           `Effect size r (magnitude)` = effect_size_report, `n` = sample_sizes)
  
  return(list(
    assumptions = assumptions_table,
    kruskal_wallis = kw_table, 
    pairwise_comparisons = dunn_table
  ))
}
```

```{r}
# ---------- Assumptions & omnibus for SITE ----------
assess_site_assumptions <- function(data, traits) {
  purrr::map_dfr(traits, function(tr) {
    df <- data %>% select(site, value = all_of(tr)) %>% drop_na()
    if (n_distinct(df$site) < 2 || nrow(df) < 8) {
      return(tibble(trait = tr, shapiro_p = NA, levene_p = NA, n = nrow(df)))
    }
    # One-way ANOVA residuals for normality; Levene for variance homogeneity
    f <- lm(value ~ site, data = df)
    shapiro_p <- tryCatch(shapiro.test(residuals(f))$p.value, error = function(e) NA)
    lev <- tryCatch(car::leveneTest(value ~ site, data = df), error = function(e) NULL)
    levene_p <- if (!is.null(lev)) lev$`Pr(>F)`[1] else NA
    tibble(trait = tr, shapiro_p = shapiro_p, levene_p = levene_p, n = nrow(df))
  }) %>%
  mutate(
    normal = ifelse(is.na(shapiro_p), "Unknown", ifelse(shapiro_p >= 0.05, "OK", "Violated")),
    homoskedastic = ifelse(is.na(levene_p), "Unknown", ifelse(levene_p >= 0.05, "OK", "Violated")),
    branch = case_when(
      normal == "OK" & homoskedastic == "OK" ~ "ANOVA",
      normal == "OK" & homoskedastic == "Violated" ~ "Welch",
      TRUE ~ "Kruskal"
    )
  )
}

run_site_omnibus <- function(data, traits, assumptions_tbl) {
  bind_rows(lapply(traits, function(tr) {
    df <- data %>% select(site, value = all_of(tr)) %>% drop_na()
    if (n_distinct(df$site) < 2) {
      return(tibble(trait = tr, test = NA, stat = NA, df1 = NA, df2 = NA, p = NA))
    }
    branch <- assumptions_tbl %>% filter(trait == tr) %>% pull(branch)
    if (branch == "ANOVA") {
      fit <- aov(value ~ site, data = df)
      a <- summary(fit)[[1]]
      tibble(trait = tr, test = "ANOVA", stat = unname(a$`F value`[1]),
             df1 = a$Df[1], df2 = a$Df[2], p = a$`Pr(>F)`[1])
    } else if (branch == "Welch") {
      w <- oneway.test(value ~ site, data = df, var.equal = FALSE)
      tibble(trait = tr, test = "Welch ANOVA", stat = unname(w$statistic),
             df1 = unname(w$parameter[1]), df2 = unname(w$parameter[2]), p = w$p.value)
    } else {
      kw <- kruskal.test(value ~ site, data = df)
      tibble(trait = tr, test = "Kruskal-Wallis", stat = unname(kw$statistic),
             df1 = length(unique(df$site)) - 1, df2 = NA, p = kw$p.value)
    }
  }))
}

# ---------- Post-hoc for SITE ----------
site_posthoc <- function(data, traits, assumptions_tbl, p_adjust = "bonferroni") {
  out <- list()
  for (tr in traits) {
    df <- data %>% select(site, value = all_of(tr)) %>% drop_na()
    if (n_distinct(df$site) < 2) next
    branch <- assumptions_tbl %>% filter(trait == tr) %>% pull(branch)
    if (branch == "ANOVA") {
      ph <- rstatix::tukey_hsd(aov(value ~ site, data = df)) %>%
        mutate(trait = tr, method = "Tukey HSD")
      out[[tr]] <- ph
    } else if (branch == "Welch") {
      # Games-Howell for unequal variances
      ph <- rstatix::games_howell_test(df, value ~ site) %>%
        mutate(trait = tr, method = "Games-Howell")
      out[[tr]] <- ph
    } else {
      ph <- rstatix::dunn_test(df, value ~ site, p.adjust.method = p_adjust) %>%
        mutate(trait = tr, method = paste0("Dunn (", p_adjust, ")"))
      out[[tr]] <- ph
    }
  }
  bind_rows(out)
}
```


# RHMA Analysis

```{r rhma-analysis}
# Read and clean RHMA data
rhma_raw <- read_csv("C:\\Users\\sarai\\OneDrive\\Email attachments\\Documents\\UVI\\Thesis.Work\\SargMangs\\Data/RHMA_IntakeData.csv", 
                     show_col_types = FALSE) %>% 
  clean_names()

rhma_traits <- c("diameter", "epi_length", "hypo_length", "total_height", "mass")

rhma_clean <- rhma_raw %>%
  mutate(
    intake_date = parse_mdy_relaxed(intake_date),
    collection_date_clean = str_extract(collection_date, "\\b\\d{1,2}/\\d{1,2}(?:/\\d{2,4})?\\b"),
    collection_date_clean = if_else(
      str_detect(collection_date_clean, "^\\d{1,2}/\\d{1,2}$"),
      paste0(collection_date_clean, "/2024"),
      collection_date_clean
    ),
    collection_date = suppressWarnings(mdy(collection_date_clean)),
    across(all_of(rhma_traits), clean_numeric),
    treatment = dplyr::recode(treatment, !!!treatment_map)
  ) %>%
  filter(!is.na(intake_date)) %>%
  arrange(prop_id, intake_date) %>%
  group_by(prop_id) %>% 
  slice(1) %>% 
  ungroup()

rhma_clean <- .make_site_factor(rhma_clean)

# Outlier detection
rhma_outliers <- detect_outliers(rhma_clean, rhma_traits)
cat("RHMA outliers detected:", nrow(rhma_outliers), "\n")

# Summary statistics
rhma_summary <- rhma_clean %>%
  pivot_longer(all_of(rhma_traits), names_to = "trait") %>%
  group_by(site, treatment, trait) %>%
  summarise(
    n = sum(!is.na(value)),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(mean_sd = sprintf("%.2f ± %.2f", mean, sd))

knitr::kable(rhma_summary %>% select(site, treatment, trait, n, mean_sd),
             caption = "RHMA Summary Statistics")

# Assumption checks
rhma_assumptions <- check_assumptions(rhma_clean, rhma_traits) %>%
  mutate(
    normal = case_when(shapiro_p >= 0.05 ~ "OK", shapiro_p < 0.05 ~ "Violated", TRUE ~ "Unknown"),
    homogeneous = case_when(levene_p >= 0.05 ~ "OK", levene_p < 0.05 ~ "Violated", TRUE ~ "Unknown")
  )

knitr::kable(rhma_assumptions, digits = 4, caption = "RHMA Assumption Checks")

# Statistical tests
needs_nonparametric <- any(rhma_assumptions$shapiro_p < 0.05 | rhma_assumptions$levene_p < 0.05, na.rm = TRUE)

if (needs_nonparametric) {
  cat("Running nonparametric tests for RHMA\n")
  rhma_tests <- run_nonparametric_tests(rhma_clean, rhma_traits)
  
  # Debug: Check data structure
  cat("Dunn test results structure:\n")
  cat("Rows in dunn_pairwise:", nrow(rhma_tests$dunn_pairwise), "\n")
  if (nrow(rhma_tests$dunn_pairwise) > 0) {
    cat("Column names:", paste(names(rhma_tests$dunn_pairwise), collapse = ", "), "\n")
  }
  
  # Significant results only
  rhma_sig <- rhma_tests$dunn_pairwise %>%
    mutate(comparison = paste(group1, "vs", group2)) %>%
    filter(!is.na(p.adj) & p.adj < 0.05) %>%
    arrange(trait, site, p.adj)
  
  if (nrow(rhma_sig) > 0) {
    knitr::kable(rhma_sig %>% select(trait, site, comparison, p.adj),
                 caption = "RHMA Significant Pairwise Comparisons (p < 0.05)")
  } else {
    cat("No significant pairwise differences found for RHMA\n")
  }
}

# Create plots
p_rhma <- create_boxplots(rhma_clean, c("total_height", "epi_length", "diameter", "mass"), "RHMA", trait_units)
print(p_rhma)
```

```{r}
# ---------- RHMA: Site effect on baseline traits ----------
rhma_site_assump <- assess_site_assumptions(rhma_clean, rhma_traits)
knitr::kable(rhma_site_assump, digits = 4, caption = "RHMA: Site-Only Assumption Checks")

rhma_site_omni <- run_site_omnibus(rhma_clean, rhma_traits, rhma_site_assump) %>%
  mutate(significant = ifelse(p < 0.05, "Yes", "No"))
knitr::kable(rhma_site_omni, digits = 4, caption = "RHMA: Site Omnibus Tests (Baseline)")

rhma_site_ph <- site_posthoc(rhma_clean, rhma_traits, rhma_site_assump, p_adjust = "bonferroni")
# Show only significant
rhma_site_ph_sig <- rhma_site_ph %>%
  mutate(p = ifelse(!is.na(p.adj), p.adj, p.adj.signif)) %>%
  filter((!is.na(p.adj) & p.adj < 0.05) | (!is.na(p) & suppressWarnings(as.numeric(p)) < 0.05))
if (nrow(rhma_site_ph_sig) > 0) {
  knitr::kable(rhma_site_ph_sig %>%
                 select(trait, method, group1, group2, p.adj, p.adj.signif),
               digits = 4,
               caption = "RHMA: Significant Site Post-hoc Comparisons")
} else {
  cat("RHMA: No significant site pairwise differences after correction.\n")
}
```

```{r}
# Ensure treatment factor order
rhma_clean <- rhma_clean %>%
  mutate(treatment = factor(treatment,
    levels = c("Soil", "Crushed glass", "25% SG", "75% SG", "100% Sargassum (SG)")
  ))

# Long data for traits shown in p_rhma
rhma_long <- rhma_clean %>%
  pivot_longer(all_of(c("total_height","epi_length","diameter","mass")), names_to = "trait", values_to = "value")

# Per-panel y positions (site × trait)
rhma_ypos <- .panel_y_positions(rhma_long, panel_vars = c("site","trait"), x_var = "treatment")

# Dunn + CLDs within each panel
rhma_letters <- rhma_long %>%
  drop_na(value) %>%
  group_by(site, trait) %>%
  group_modify(~{
    if (n_distinct(.x$treatment) < 2) return(tibble())
    pairs <- rstatix::dunn_test(.x, value ~ treatment, p.adjust.method = "bonferroni")
    cld   <- .cld_from_pairs(pairs, level_order = levels(.x$treatment))
    cld
  }) %>%
  ungroup() %>%
  rename(treatment = group) %>%
  left_join(rhma_ypos, by = c("site","trait")) %>%
  mutate(label = Letters)

# Add to plot
p_rhma_letters <- p_rhma +
  geom_text(
    data = rhma_letters,
    aes(x = treatment, y = y_pos_panel, label = label),
    size = 3, vjust = 0
  ) +
  expand_limits(y = max(rhma_letters$y_pos_panel, na.rm = TRUE))

print(p_rhma_letters)
```


```{r comprehensive-rhma-analysis}
# Generate complete statistical report for RHMA
cat("Generating comprehensive RHMA statistical report...\n\n")

# Run the complete analysis
rhma_complete <- generate_complete_report(rhma_clean, rhma_traits, "RHMA")

# Create publication-ready tables
rhma_tables <- create_publication_table(rhma_complete, "RHMA")

# Save tables to output directory
save_publication_tables(rhma_tables, "RHMA", params$out_dir)

# Display formatted tables
cat("\n=== PUBLICATION-READY TABLES FOR RHMA ===\n\n")

cat("Table 1: Assumption Testing Results\n")
knitr::kable(rhma_tables$assumptions, caption = "RHMA: Tests of Statistical Assumptions")

cat("\nTable 2: Kruskal-Wallis Test Results\n") 
knitr::kable(rhma_tables$kruskal_wallis, caption = "RHMA: Overall Treatment Effects by Site")

cat("\nTable 3: Significant Pairwise Comparisons\n")
knitr::kable(rhma_tables$pairwise_comparisons, caption = "RHMA: Significant Post-hoc Comparisons (Bonferroni-corrected)")
```


```{r save-rhma-results, eval=FALSE, include=FALSE}
# Save RHMA results for sharing
write_csv(rhma_summary, "rhma_summary_stats.csv")
write_csv(rhma_assumptions, "rhma_assumption_checks.csv")

if (exists("rhma_tests")) {
  write_csv(rhma_tests$kruskal_wallis, "rhma_kruskal_wallis.csv")
  write_csv(rhma_tests$dunn_pairwise, "rhma_dunn_pairwise.csv")
}

if (exists("rhma_sig") && nrow(rhma_sig) > 0) {
  write_csv(rhma_sig, "rhma_significant_comparisons.csv")
}

# Capture console output
sink("rhma_analysis_output.txt")
cat("=== RHMA ANALYSIS RESULTS ===\n\n")
cat("Summary Statistics:\n")
print(rhma_summary)
cat("\n\nAssumption Checks:\n")
print(rhma_assumptions)
if (exists("rhma_sig")) {
  cat("\n\nSignificant Comparisons:\n")
  print(rhma_sig)
}
sink()
```

# LARA Analysis

```{r lara-analysis}
# Read and clean LARA data
lara_raw <- read_csv("C:\\Users\\sarai\\OneDrive\\Email attachments\\Documents\\UVI\\Thesis.Work\\SargMangs\\Data/LARA_IntakeData.csv", 
                     show_col_types = FALSE) %>% 
  clean_names()

lara_traits <- c("width", "prop_length", "rad_length", "total_length", "mass")

lara_clean <- lara_raw %>%
  mutate(
    intake_date = parse_mdy_relaxed(intake_date),
    collection_date_clean = str_extract(collection_date, "\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b"),
    collection_date = parse_mdy_relaxed(collection_date_clean),
    across(all_of(lara_traits), clean_numeric),
    treatment = dplyr::recode(treatment, !!!treatment_map),
    species = "LARA"
  ) %>%
  filter(!is.na(intake_date)) %>%
  arrange(prop_id, intake_date) %>%
  group_by(prop_id) %>% 
  slice(1) %>% 
  ungroup()

lara_clean <- .make_site_factor(lara_clean)

# Outlier detection
lara_outliers <- detect_outliers(lara_clean, lara_traits)
cat("LARA outliers detected:", nrow(lara_outliers), "\n")

# Summary statistics
lara_summary <- lara_clean %>%
  pivot_longer(all_of(lara_traits), names_to = "trait") %>%
  group_by(site, treatment, trait) %>%
  summarise(
    n = sum(!is.na(value)),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(mean_sd = sprintf("%.2f ± %.2f", mean, sd))

knitr::kable(lara_summary %>% select(site, treatment, trait, n, mean_sd),
             caption = "LARA Summary Statistics")

# Assumption checks
lara_assumptions <- check_assumptions(lara_clean, lara_traits) %>%
  mutate(
    normal = case_when(shapiro_p >= 0.05 ~ "OK", shapiro_p < 0.05 ~ "Violated", TRUE ~ "Unknown"),
    homogeneous = case_when(levene_p >= 0.05 ~ "OK", levene_p < 0.05 ~ "Violated", TRUE ~ "Unknown")
  )

knitr::kable(lara_assumptions, digits = 4, caption = "LARA Assumption Checks")

# Statistical tests (assuming nonparametric needed)
cat("Running nonparametric tests for LARA\n")
lara_tests <- run_nonparametric_tests(lara_clean, lara_traits)

# Debug: Check data structure
cat("LARA Dunn test results structure:\n")
cat("Rows in dunn_pairwise:", nrow(lara_tests$dunn_pairwise), "\n")
if (nrow(lara_tests$dunn_pairwise) > 0) {
  cat("Column names:", paste(names(lara_tests$dunn_pairwise), collapse = ", "), "\n")
}

# Significant results only
lara_sig <- lara_tests$dunn_pairwise %>%
  mutate(comparison = paste(group1, "vs", group2)) %>%
  filter(!is.na(p.adj) & p.adj < 0.05) %>%
  arrange(trait, site, p.adj)

if (nrow(lara_sig) > 0) {
  knitr::kable(lara_sig %>% select(trait, site, comparison, p.adj),
               caption = "LARA Significant Pairwise Comparisons (p < 0.05)")
} else {
  cat("No significant pairwise differences found for LARA\n")
}

# Create plots
p_lara <- create_boxplots(lara_clean, c("total_length", "width", "mass"), "LARA", trait_units)
print(p_lara)
```

```{r}
# ---------- LARA: Site effect on baseline traits ----------
lara_site_assump <- assess_site_assumptions(lara_clean, lara_traits)
knitr::kable(lara_site_assump, digits = 4, caption = "LARA: Site-Only Assumption Checks")

lara_site_omni <- run_site_omnibus(lara_clean, lara_traits, lara_site_assump) %>%
  mutate(significant = ifelse(p < 0.05, "Yes", "No"))
knitr::kable(lara_site_omni, digits = 4, caption = "LARA: Site Omnibus Tests (Baseline)")

lara_site_ph <- site_posthoc(lara_clean, lara_traits, lara_site_assump, p_adjust = "bonferroni")
lara_site_ph_sig <- lara_site_ph %>%
  mutate(p = ifelse(!is.na(p.adj), p.adj, p.adj.signif)) %>%
  filter((!is.na(p.adj) & p.adj < 0.05) | (!is.na(p) & suppressWarnings(as.numeric(p)) < 0.05))
if (nrow(lara_site_ph_sig) > 0) {
  knitr::kable(lara_site_ph_sig %>%
                 select(trait, method, group1, group2, p.adj, p.adj.signif),
               digits = 4,
               caption = "LARA: Significant Site Post-hoc Comparisons")
} else {
  cat("LARA: No significant site pairwise differences after correction.\n")
}
```


```{r}
# Ensure same treatment factor as your plot
lara_clean <- lara_clean %>%
  mutate(treatment = factor(treatment,
    levels = c("Soil", "Crushed glass", "25% SG", "75% SG", "100% Sargassum (SG)")
  ))

# Long data for traits shown in p_lara
lara_long <- lara_clean %>%
  pivot_longer(all_of(c("total_length","width","mass")), names_to = "trait", values_to = "value")

# Get per-panel y positions (site × trait)
lara_ypos <- .panel_y_positions(lara_long, panel_vars = c("site","trait"), x_var = "treatment")

# Dunn (Bonferroni) within each site × trait, then CLDs
lara_letters <- lara_long %>%
  drop_na(value) %>%
  group_by(site, trait) %>%
  group_modify(~{
    if (n_distinct(.x$treatment) < 2) return(tibble())
    pairs <- rstatix::dunn_test(.x, value ~ treatment, p.adjust.method = "bonferroni")
    cld   <- .cld_from_pairs(pairs, level_order = levels(.x$treatment))
    cld
  }) %>%
  ungroup() %>%
  rename(treatment = group) %>%
  left_join(lara_ypos, by = c("site","trait")) %>%
  mutate(label = Letters)

# Add letters to your existing plot p_lara
p_lara_letters <- p_lara +
  geom_text(
    data = lara_letters,
    aes(x = treatment, y = y_pos_panel, label = label),
    size = 3, vjust = 0
  ) +
  expand_limits(y = max(lara_letters$y_pos_panel, na.rm = TRUE))

print(p_lara_letters)
```


```{r comprehensive-lara-analysis}
# Generate complete statistical report for LARA
cat("Generating comprehensive LARA statistical report...\n\n")

# Run the complete analysis
lara_complete <- generate_complete_report(lara_clean, lara_traits, "LARA")

# Create publication-ready tables
lara_tables <- create_publication_table(lara_complete, "LARA")

# Save tables to output directory
save_publication_tables(lara_tables, "LARA", params$out_dir)

# Display formatted tables
cat("\n=== PUBLICATION-READY TABLES FOR LARA ===\n\n")

cat("Table 4: Assumption Testing Results\n")
knitr::kable(lara_tables$assumptions, caption = "LARA: Tests of Statistical Assumptions")

cat("\nTable 5: Kruskal-Wallis Test Results\n")
knitr::kable(lara_tables$kruskal_wallis, caption = "LARA: Overall Treatment Effects by Site")

cat("\nTable 6: Significant Pairwise Comparisons\n")
knitr::kable(lara_tables$pairwise_comparisons, caption = "LARA: Significant Post-hoc Comparisons (Bonferroni-corrected)")
```

```{r save-lara-results, eval=FALSE, include=FALSE}
# Save LARA results for sharing
write_csv(lara_summary, "lara_summary_stats.csv")
write_csv(lara_assumptions, "lara_assumption_checks.csv")

if (exists("lara_tests")) {
  write_csv(lara_tests$kruskal_wallis, "lara_kruskal_wallis.csv")
  write_csv(lara_tests$dunn_pairwise, "lara_dunn_pairwise.csv")
}

if (exists("lara_sig") && nrow(lara_sig) > 0) {
  write_csv(lara_sig, "lara_significant_comparisons.csv")
}

# Capture console output
sink("lara_analysis_output.txt")
cat("=== LARA ANALYSIS RESULTS ===\n\n")
cat("Summary Statistics:\n")
print(lara_summary)
cat("\n\nAssumption Checks:\n")
print(lara_assumptions)
if (exists("lara_sig")) {
  cat("\n\nSignificant Comparisons:\n")
  print(lara_sig)
}
sink()
```

# Summary

```{r summary}
cat("Analysis Summary:\n")
cat("================\n")
cat("RHMA traits analyzed:", length(rhma_traits), "\n")
cat("LARA traits analyzed:", length(lara_traits), "\n")
cat("Total samples - RHMA:", nrow(rhma_clean), "| LARA:", nrow(lara_clean), "\n")
cat("Outliers detected - RHMA:", nrow(rhma_outliers), "| LARA:", nrow(lara_outliers), "\n")

if (exists("rhma_sig")) {
  cat("RHMA significant comparisons:", nrow(rhma_sig), "\n")
}
if (exists("lara_sig")) {
  cat("LARA significant comparisons:", nrow(lara_sig), "\n")
}

sessionInfo()
```

```{r}
# ─────────────────────────────────────────────────────────────
# Setup
# ─────────────────────────────────────────────────────────────
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      fig.width = 9, fig.height = 6)

suppressPackageStartupMessages({
  library(tidyverse)
  library(lubridate)
  library(janitor)
  library(car)
  library(rstatix)
  library(multcompView)
  library(FSA)
  library(forcats)
})
set.seed(20250901)

# Palette / labels
okabe_ito <- c("#E69F00","#56B4E9","#009E73","#F0E442","#0072B2","#D55E00","#CC79A7","#999999")
treatment_map <- c("A"="Soil","B"="Crushed glass","C"="25% SG","D"="75% SG","E"="100% Sargassum (SG)")
color_vals <- c("Soil"=okabe_ito[1],"Crushed glass"=okabe_ito[6],"25% SG"=okabe_ito[3],
                "75% SG"=okabe_ito[2],"100% Sargassum (SG)"=okabe_ito[7])
trait_units <- list( # for axis labels
  diameter="mm", epi_length="cm", hypo_length="cm", total_height="cm", mass="g",
  width="mm", prop_length="cm", rad_length="cm", total_length="cm"
)

# Output folder (works in Rmd & script)
if (!exists("params") || is.null(params$out_dir)) params <- list(out_dir="analysis_outputs")
dir.create(params$out_dir, showWarnings = FALSE, recursive = TRUE)

# ─────────────────────────────────────────────────────────────
# Helpers
# ─────────────────────────────────────────────────────────────
parse_mdy_relaxed <- function(x) parse_date_time(x, orders=c("mdy","mdy HM","mdy HMS"))
clean_numeric      <- function(x) suppressWarnings(as.numeric(str_replace_all(x, ",", "")))
make_site_factor   <- function(df) df %>% mutate(site = fct_drop(as.factor(site)))

detect_outliers <- function(data, traits) {
  data |>
    pivot_longer(all_of(traits), names_to="trait", values_to="value") |>
    group_by(trait) |>
    mutate(iqr = IQR(value, na.rm=TRUE),
           Q1 = quantile(value, .25, na.rm=TRUE),
           Q3 = quantile(value, .75, na.rm=TRUE),
           is_outlier = value < (Q1-3*iqr) | value > (Q3+3*iqr)) |>
    ungroup() |>
    filter(is_outlier & !is.na(value))
}

# Site×Trait assumption branch (ANOVA / Welch / Kruskal) used for baseline site tests
assess_site_assumptions <- function(data, traits){
  map_dfr(traits, function(tr){
    df <- data |> select(site, value = all_of(tr)) |> drop_na()
    if (n_distinct(df$site) < 2 || nrow(df) < 8)
      return(tibble(trait=tr, shapiro_p=NA, levene_p=NA, n=nrow(df)))
    f  <- lm(value ~ site, data=df)
    sp <- tryCatch(shapiro.test(residuals(f))$p.value, error=function(e) NA)
    lp <- tryCatch(car::leveneTest(value ~ site, data=df)$`Pr(>F)`[1], error=function(e) NA)
    tibble(trait=tr, shapiro_p=sp, levene_p=lp, n=nrow(df))
  }) |>
  mutate(
    normal        = if_else(is.na(shapiro_p), "Unknown", if_else(shapiro_p>=.05,"OK","Violated")),
    homoskedastic = if_else(is.na(levene_p),  "Unknown", if_else(levene_p>=.05,"OK","Violated")),
    branch        = case_when(normal=="OK" & homoskedastic=="OK" ~ "ANOVA",
                              normal=="OK" & homoskedastic=="Violated" ~ "Welch",
                              TRUE ~ "Kruskal"))
}

run_site_omnibus <- function(data, traits, assumptions_tbl){
  bind_rows(lapply(traits, function(tr){
    df <- data |> select(site, value = all_of(tr)) |> drop_na()
    if (n_distinct(df$site) < 2) return(tibble(trait=tr, test=NA, stat=NA, df1=NA, df2=NA, p=NA))
    branch <- assumptions_tbl |> filter(trait==tr) |> pull(branch)
    if (branch=="ANOVA") {
      a <- summary(aov(value ~ site, data=df))[[1]]
      tibble(trait=tr, test="ANOVA", stat=unname(a$`F value`[1]),
             df1=a$Df[1], df2=a$Df[2], p=a$`Pr(>F)`[1])
    } else if (branch=="Welch") {
      w <- oneway.test(value ~ site, data=df, var.equal=FALSE)
      tibble(trait=tr, test="Welch ANOVA", stat=unname(w$statistic),
             df1=unname(w$parameter[1]), df2=unname(w$parameter[2]), p=w$p.value)
    } else {
      kw <- kruskal.test(value ~ site, data=df)
      tibble(trait=tr, test="Kruskal-Wallis", stat=unname(kw$statistic),
             df1=length(unique(df$site))-1, df2=NA, p=kw$p.value)
    }
  })) |>
  mutate(significant = if_else(p < .05, "Yes", "No"))
}

site_posthoc <- function(data, traits, assumptions_tbl, p_adjust="bonferroni"){
  out <- list()
  for (tr in traits){
    df <- data |> select(site, value = all_of(tr)) |> drop_na()
    if (n_distinct(df$site) < 2) next
    method <- (assumptions_tbl |> filter(trait==tr) |> pull(branch))[1]
    out[[tr]] <-
      if (identical(method,"ANOVA"))
        tukey_hsd(aov(value ~ site, data=df)) |> mutate(trait=tr, method="Tukey HSD")
      else if (identical(method,"Welch"))
        games_howell_test(df, value ~ site) |> mutate(trait=tr, method="Games-Howell")
      else
        dunn_test(df, value ~ site, p.adjust.method=p_adjust) |>
          mutate(trait=tr, method=paste0("Dunn (", p_adjust, ")"))
  }
  bind_rows(out)
}

# Compute CLD letters from a pairwise table (group1, group2, p.adj)
.cld_from_pairs <- function(pairs_tbl, level_order) {
  if (nrow(pairs_tbl) == 0) {
    return(tibble(group = factor(level_order, levels = level_order), Letters = ""))
  }
  # Build a full p-value matrix in the specified order
  lv <- level_order
  M <- matrix(1, nrow = length(lv), ncol = length(lv), dimnames = list(lv, lv))
  for (i in seq_len(nrow(pairs_tbl))) {
    g1 <- as.character(pairs_tbl$group1[i])
    g2 <- as.character(pairs_tbl$group2[i])
    p  <- as.numeric(pairs_tbl$p.adj[i])
    if (!is.na(g1) && !is.na(g2) && !is.na(p) && g1 %in% lv && g2 %in% lv) {
      M[g1, g2] <- p
      M[g2, g1] <- p
    }
  }
  # multcompLetters wants a named vector of p-values for all pairs (upper triangle)
  pv_named <- c()
  for (i in seq_along(lv)) for (j in (i+1):length(lv)) {
    if (j <= length(lv)) {
      nm <- paste(lv[i], lv[j], sep = "-")
      pv_named[nm] <- M[lv[i], lv[j]]
    }
  }
  L <- multcompView::multcompLetters(pv_named, threshold = 0.05)$Letters
  tibble(group = factor(names(L), levels = level_order),
         Letters = unname(L))
}

# y-position right above each box (per site × trait × treatment)
.get_box_y_positions <- function(data_long, panel_vars, x_var, y_var = "value", bump = 0.05) {
  data_long %>%
    group_by(across(all_of(c(panel_vars, x_var)))) %>%
    summarise(y_max = max(.data[[y_var]], na.rm = TRUE), .groups = "drop") %>%
    mutate(y_pos_box = y_max + (y_max * bump)) # e.g., 5% above the max
}

create_boxplots <- function(data, traits, species_name,
                            trait_units = NULL,
                            show_letters = TRUE,
                            p_adjust = "bonferroni",
                            bump = 0.05) {

  # default units if not provided
  if (is.null(trait_units)) {
    trait_units <- list(
      diameter="mm", epi_length="cm", hypo_length="cm", total_height="cm", mass="g",
      width="mm", prop_length="cm", rad_length="cm", total_length="cm"
    )
  }

  # long data + nice labels
  long <- data %>%
  pivot_longer(all_of(traits), names_to = "trait", values_to = "value") %>%
  mutate(
    treatment = factor(
      dplyr::recode(as.character(treatment), !!!treatment_map),
      levels = c("Soil","Crushed glass","25% SG","75% SG","100% Sargassum (SG)")
    )
  ) %>%
  rowwise() %>%
  mutate(
    trait_label = {
      base <- stringr::str_to_title(gsub("_"," ", trait))
      if (trait %in% names(trait_units)) paste0(base, " (", trait_units[[trait]], ")") else base
    }
  ) %>%
  ungroup()

  # base plot
  p <- ggplot(long, aes(x = treatment, y = value, fill = treatment)) +
    geom_boxplot(outlier.alpha = 0.5, alpha = 0.7) +
    geom_jitter(width = 0.15, alpha = 0.4, size = 1) +
    scale_fill_manual(values = color_vals) +
    facet_grid(trait_label ~ site, scales = "free_y") +
    labs(x = "Treatment", y = "Measurement") +
    theme_bw(base_size = 11) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none",
      strip.text = element_text(size = 10),
      strip.text.y = element_text(size = 9)
    )

  if (!show_letters) return(p)

  # y positions right above each box (site × trait × treatment)
  ypos <- .get_box_y_positions(
    data_long  = long,
    panel_vars = c("site","trait_label"),
    x_var      = "treatment",
    y_var      = "value",
    bump       = bump
  )

  # Dunn (Bonferroni) within each site × trait; turn into CLDs
  letters_df <- long %>%
    drop_na(value) %>%
    group_by(site, trait_label) %>%
    group_modify(~{
      if (n_distinct(.x$treatment) < 2) return(tibble())
      # safer: catch edge cases
      pairs <- tryCatch(
        rstatix::dunn_test(.x, value ~ treatment, p.adjust.method = p_adjust),
        error = function(e) tibble(group1 = character(), group2 = character(), p.adj = numeric())
      )
      cld <- .cld_from_pairs(pairs, level_order = levels(.x$treatment))
      cld
    }) %>%
    ungroup() %>%
    rename(treatment = group) %>%
    left_join(ypos, by = c("site","trait_label","treatment")) %>%
    distinct(site, trait_label, treatment, .keep_all = TRUE) %>%  # avoid duplicates
    mutate(label = Letters)

  # add letters just above the boxes
  p + geom_text(
        data = letters_df,
        aes(x = treatment, y = y_pos_box, label = label),
        size = 3, vjust = 0
      )
}

# Convenience: summary stats (site×treatment×trait)
summarise_traits <- function(df, traits){
  df |>
    pivot_longer(all_of(traits), names_to="trait") |>
    group_by(site, treatment, trait) |>
    summarise(n=sum(!is.na(value)), mean=mean(value, na.rm=TRUE),
              sd=sd(value, na.rm=TRUE), .groups="drop") |>
    mutate(mean_sd = sprintf("%.2f ± %.2f", mean, sd))
}

# ─────────────────────────────────────────────────────────────
# RHMA
# ─────────────────────────────────────────────────────────────
rhma_path <- "C:/Users/sarai/OneDrive/Email attachments/Documents/UVI/Thesis.Work/SargMangs/Data/RHMA_IntakeData.csv"

rhma_traits <- c("diameter","epi_length","hypo_length","total_height","mass")
rhma_raw <- read_csv(rhma_path, show_col_types = FALSE) |> clean_names()

rhma_clean <- rhma_raw |>
  mutate(
    intake_date = parse_mdy_relaxed(intake_date),
    collection_date_clean = str_extract(collection_date, "\\b\\d{1,2}/\\d{1,2}(?:/\\d{2,4})?\\b"),
    collection_date_clean = if_else(str_detect(collection_date_clean, "^\\d{1,2}/\\d{1,2}$"),
                                    paste0(collection_date_clean,"/2024"), collection_date_clean),
    collection_date = suppressWarnings(mdy(collection_date_clean)),
    across(all_of(rhma_traits), clean_numeric),
    treatment = dplyr::recode(as.character(treatment), !!!treatment_map)
  ) |>
  filter(!is.na(intake_date)) |>
  arrange(prop_id, intake_date) |>
  group_by(prop_id) |> slice(1) |> ungroup() |>
  make_site_factor()

rhma_outliers <- detect_outliers(rhma_clean, rhma_traits)
cat("RHMA outliers detected:", nrow(rhma_outliers), "\n")

# Site-only baseline tests (biology-first framing)
rhma_site_assump <- assess_site_assumptions(rhma_clean, rhma_traits)
rhma_site_omni   <- run_site_omnibus(rhma_clean, rhma_traits, rhma_site_assump)
rhma_site_ph     <- site_posthoc(rhma_clean, rhma_traits, rhma_site_assump, p_adjust="bonferroni")

knitr::kable(summarise_traits(rhma_clean, rhma_traits) |> select(site,treatment,trait,n,mean_sd),
             caption="RHMA Summary Statistics")
knitr::kable(rhma_site_assump, digits=4, caption="RHMA: Site-Only Assumption Checks")
knitr::kable(rhma_site_omni,   digits=4, caption="RHMA: Site Omnibus Tests (Baseline)")
if (nrow(rhma_site_ph)) {
  knitr::kable(rhma_site_ph |> filter(!is.na(p.adj) & p.adj < .05) |>
                 select(trait,method,group1,group2,p.adj,p.adj.signif),
               caption="RHMA: Significant Site Post-hoc Comparisons")
}

p_rhma <- create_boxplots(rhma_clean, c("total_height","epi_length","diameter","mass"), "RHMA", trait_units)
print(p_rhma)

# ─────────────────────────────────────────────────────────────
# LARA
# ─────────────────────────────────────────────────────────────
lara_path <- "C:/Users/sarai/OneDrive/Email attachments/Documents/UVI/Thesis.Work/SargMangs/Data/LARA_IntakeData.csv"

lara_traits <- c("width","prop_length","rad_length","total_length","mass")
lara_raw <- read_csv(lara_path, show_col_types = FALSE) |> clean_names()

lara_clean <- lara_raw |>
  mutate(
    intake_date = parse_mdy_relaxed(intake_date),
    collection_date_clean = str_extract(collection_date, "\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b"),
    collection_date = parse_mdy_relaxed(collection_date_clean),
    across(all_of(lara_traits), clean_numeric),
    treatment = dplyr::recode(as.character(treatment), !!!treatment_map),
    species = "LARA"
  ) |>
  filter(!is.na(intake_date)) |>
  arrange(prop_id, intake_date) |>
  group_by(prop_id) |> slice(1) |> ungroup() |>
  make_site_factor()

lara_outliers <- detect_outliers(lara_clean, lara_traits)
cat("LARA outliers detected:", nrow(lara_outliers), "\n")

lara_site_assump <- assess_site_assumptions(lara_clean, lara_traits)
lara_site_omni   <- run_site_omnibus(lara_clean, lara_traits, lara_site_assump)
lara_site_ph     <- site_posthoc(lara_clean, lara_traits, lara_site_assump, p_adjust="bonferroni")

knitr::kable(summarise_traits(lara_clean, lara_traits) |> select(site,treatment,trait,n,mean_sd),
             caption="LARA Summary Statistics")
knitr::kable(lara_site_assump, digits=4, caption="LARA: Site-Only Assumption Checks")
knitr::kable(lara_site_omni,   digits=4, caption="LARA: Site Omnibus Tests (Baseline)")
if (nrow(lara_site_ph)) {
  knitr::kable(lara_site_ph |> filter(!is.na(p.adj) & p.adj < .05) |>
                 select(trait,method,group1,group2,p.adj,p.adj.signif),
               caption="LARA: Significant Site Post-hoc Comparisons")
}

p_lara <- create_boxplots(lara_clean, c("total_length","width","mass"), "LARA", trait_units)
print(p_lara)

# ─────────────────────────────────────────────────────────────
# Summary
# ─────────────────────────────────────────────────────────────
cat("Analysis Summary:\n================\n")
cat("RHMA traits:", length(rhma_traits), " | LARA traits:", length(lara_traits), "\n")
cat("Total samples — RHMA:", nrow(rhma_clean), " | LARA:", nrow(lara_clean), "\n")
cat("Outliers — RHMA:", nrow(rhma_outliers), " | LARA:", nrow(lara_outliers), "\n")

```


